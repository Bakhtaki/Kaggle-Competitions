{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Preliminaries","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2022-07-30T15:44:12.956236Z","iopub.execute_input":"2022-07-30T15:44:12.957000Z","iopub.status.idle":"2022-07-30T15:44:12.986824Z","shell.execute_reply.started":"2022-07-30T15:44:12.956889Z","shell.execute_reply":"2022-07-30T15:44:12.985929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install sklego","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-07-30T15:44:12.988584Z","iopub.execute_input":"2022-07-30T15:44:12.989087Z","iopub.status.idle":"2022-07-30T15:44:29.507896Z","shell.execute_reply.started":"2022-07-30T15:44:12.989056Z","shell.execute_reply":"2022-07-30T15:44:29.506541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\n\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, PowerTransformer\nfrom sklearn.mixture import GaussianMixture, BayesianGaussianMixture\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\nfrom sklego.mixture import BayesianGMMClassifier","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-30T15:44:29.509428Z","iopub.execute_input":"2022-07-30T15:44:29.509893Z","iopub.status.idle":"2022-07-30T15:44:31.555639Z","shell.execute_reply.started":"2022-07-30T15:44:29.509854Z","shell.execute_reply":"2022-07-30T15:44:31.554695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/tabular-playground-series-jul-2022/data.csv\")\ndf = df.drop(columns=\"id\")","metadata":{"execution":{"iopub.status.busy":"2022-07-30T15:44:31.559409Z","iopub.execute_input":"2022-07-30T15:44:31.560841Z","iopub.status.idle":"2022-07-30T15:44:33.121913Z","shell.execute_reply.started":"2022-07-30T15:44:31.560791Z","shell.execute_reply":"2022-07-30T15:44:33.120653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"int_cols = [i for i in df.columns if df[i].dtype == int]\nint_cols","metadata":{"execution":{"iopub.status.busy":"2022-07-30T15:44:33.124743Z","iopub.execute_input":"2022-07-30T15:44:33.125063Z","iopub.status.idle":"2022-07-30T15:44:33.135585Z","shell.execute_reply.started":"2022-07-30T15:44:33.125034Z","shell.execute_reply":"2022-07-30T15:44:33.134551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"float_cols = [i for i in df.columns if df[i].dtype == float]\nfloat_cols","metadata":{"execution":{"iopub.status.busy":"2022-07-30T15:44:33.137684Z","iopub.execute_input":"2022-07-30T15:44:33.138069Z","iopub.status.idle":"2022-07-30T15:44:33.149360Z","shell.execute_reply.started":"2022-07-30T15:44:33.138036Z","shell.execute_reply":"2022-07-30T15:44:33.148235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"transformer = PowerTransformer()\nX_scaled = transformer.fit_transform(df)\nX_scaled = pd.DataFrame(X_scaled, columns = df.columns)","metadata":{"execution":{"iopub.status.busy":"2022-07-30T15:44:33.150989Z","iopub.execute_input":"2022-07-30T15:44:33.151688Z","iopub.status.idle":"2022-07-30T15:44:37.023918Z","shell.execute_reply.started":"2022-07-30T15:44:33.151652Z","shell.execute_reply":"2022-07-30T15:44:37.022547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# _Optimal Number of Clusters_","metadata":{}},{"cell_type":"code","source":"def components_number_multiple(max_n, n_seeds):\n    bic_scores = []\n    for n in range(2,max_n):\n        bic_scores_n = []\n        for seed in range(n_seeds):\n            gmm = GaussianMixture(n_components=n, covariance_type = 'full', n_init=3, random_state=seed)\n            gmm.fit(X_scaled)\n            bic_scores_n.append(gmm.bic(X_scaled))\n        bic_scores.append(bic_scores_n)\n    return bic_scores","metadata":{"execution":{"iopub.status.busy":"2022-07-30T15:44:37.025638Z","iopub.execute_input":"2022-07-30T15:44:37.026541Z","iopub.status.idle":"2022-07-30T15:44:37.034177Z","shell.execute_reply.started":"2022-07-30T15:44:37.026499Z","shell.execute_reply":"2022-07-30T15:44:37.032680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_components_number_multiple(max_n, n_seeds):\n    bic_scores = components_number_multiple(max_n + 1, n_seeds)\n    bic_df = pd.DataFrame(data = bic_scores).T\n    bic_df.columns = range(2,max_n+1)\n    \n    f,ax = plt.subplots(figsize=(20,7))\n    for i in range(n_seeds):\n        sns.lineplot(x=bic_df.columns, y=bic_df.loc[i].values)\n    ax.set_xticks(range(2,max_n+1))\n    \n    return bic_df","metadata":{"execution":{"iopub.status.busy":"2022-07-30T15:44:37.035670Z","iopub.execute_input":"2022-07-30T15:44:37.036099Z","iopub.status.idle":"2022-07-30T15:44:37.046988Z","shell.execute_reply.started":"2022-07-30T15:44:37.036061Z","shell.execute_reply":"2022-07-30T15:44:37.045733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# a = plot_components_number_multiple(max_n = 15, n_seeds = 10)","metadata":{"execution":{"iopub.status.busy":"2022-07-30T15:44:37.048359Z","iopub.execute_input":"2022-07-30T15:44:37.048722Z","iopub.status.idle":"2022-07-30T15:44:37.058308Z","shell.execute_reply.started":"2022-07-30T15:44:37.048689Z","shell.execute_reply":"2022-07-30T15:44:37.057436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Importance","metadata":{}},{"cell_type":"code","source":"bgmm = BayesianGaussianMixture(n_components=7, covariance_type = 'full', n_init=3, random_state=4)\npredicted_class = bgmm.fit_predict(X_scaled)\ndf[\"class\"] = predicted_class","metadata":{"execution":{"iopub.status.busy":"2022-07-30T15:44:37.059857Z","iopub.execute_input":"2022-07-30T15:44:37.060403Z","iopub.status.idle":"2022-07-30T15:47:33.240070Z","shell.execute_reply.started":"2022-07-30T15:44:37.060369Z","shell.execute_reply":"2022-07-30T15:47:33.238724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualising Feature Importance","metadata":{}},{"cell_type":"markdown","source":"### Continous  features","metadata":{}},{"cell_type":"code","source":"f,ax = plt.subplots(figsize=(25,50))\nfor n,feature in enumerate(float_cols):\n    plt.subplot(8,3,n+1)\n    sns.kdeplot(data=df, x=feature, hue=\"class\", palette=sns.color_palette(\"hls\", 7));","metadata":{"execution":{"iopub.status.busy":"2022-07-30T15:47:33.246361Z","iopub.execute_input":"2022-07-30T15:47:33.250143Z","iopub.status.idle":"2022-07-30T15:47:53.494742Z","shell.execute_reply.started":"2022-07-30T15:47:33.250082Z","shell.execute_reply":"2022-07-30T15:47:53.493875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Categorial features","metadata":{}},{"cell_type":"code","source":"f,ax = plt.subplots(figsize=(25,20))\nfor n,feature in enumerate(int_cols):\n    ax = plt.subplot(3,3,n+1)\n    sns.kdeplot(data=df, x=feature, hue=\"class\", bw_adjust=2, palette=sns.color_palette(\"hls\", 7));\n    ax.set_xlim([-2,30])","metadata":{"execution":{"iopub.status.busy":"2022-07-30T15:47:53.495837Z","iopub.execute_input":"2022-07-30T15:47:53.496812Z","iopub.status.idle":"2022-07-30T15:47:59.945629Z","shell.execute_reply.started":"2022-07-30T15:47:53.496777Z","shell.execute_reply":"2022-07-30T15:47:59.944568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_cols = ['f_07','f_08', 'f_09', 'f_10','f_11', 'f_12', 'f_13', 'f_22','f_23', 'f_24', 'f_25','f_26','f_27', 'f_28']","metadata":{"execution":{"iopub.status.busy":"2022-07-30T15:47:59.950680Z","iopub.execute_input":"2022-07-30T15:47:59.951048Z","iopub.status.idle":"2022-07-30T15:47:59.956475Z","shell.execute_reply.started":"2022-07-30T15:47:59.951014Z","shell.execute_reply":"2022-07-30T15:47:59.955559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def score_clusters(X, predictions, silhouette = True, verbose=False):\n    \"\"\"Evaluate how good our cluster label predictions are\"\"\"\n    \n    db_score = davies_bouldin_score(X=X, labels=predictions)\n\n    ch_score = calinski_harabasz_score(X=X, labels=predictions)\n    #the silhouette score is the slowest to compute ~90 secs\n    s_score = silhouette_score(X=X, labels=predictions, metric='euclidean')\n    \n    if verbose:\n        print(\"David Bouldin score: {0:0.4f}\".format(db_score))\n        print(\"Calinski Harabasz score: {0:0.3f}\".format(ch_score))\n        print(\"Silhouette score: {0:0.4f}\".format(s_score))\n        \n    return db_score, ch_score, s_score","metadata":{"execution":{"iopub.status.busy":"2022-07-30T15:47:59.957821Z","iopub.execute_input":"2022-07-30T15:47:59.958805Z","iopub.status.idle":"2022-07-30T15:47:59.967797Z","shell.execute_reply.started":"2022-07-30T15:47:59.958747Z","shell.execute_reply":"2022-07-30T15:47:59.966785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def soft_voting(predict_number, best_cols = best_cols):\n    #initialise dataframe with 0's\n    predicted_probabilities = pd.DataFrame(np.zeros((len(df),7)), columns=range(1,8))\n    # loop with a different random seeds\n    for i in range(predict_number):\n        print(\"=========\", i, \"==========\")\n        X_scaled_sample = X_scaled.sample(40000)\n        gmm = BayesianGaussianMixture(n_components=7, covariance_type = 'full', max_iter=300, init_params=\"kmeans\", n_init=3, random_state=i)\n        gmm.fit(X_scaled_sample[best_cols])\n        pred_probs = gmm.predict_proba(X_scaled[best_cols])\n        pred_probs = pd.DataFrame(pred_probs, columns=range(1,8))\n        \n        # ensuring clusters are labeled the same value at each fit\n        if i == 0:\n            initial_centers = gmm.means_\n        new_classes = []\n        for mean2 in gmm.means_:\n            #for the current center of the current gmm, find the distances to every center in the initial gmm\n            distances = [np.linalg.norm(mean1-mean2) for mean1 in initial_centers]\n            # select the class with the minimum distance\n            new_class = np.argmin(distances) + 1 #add 1 as our labels are 1-7 but index is 0-6\n            new_classes.append(new_class)\n        # if the mapping from old cluster labels to new cluster labels isn't 1 to 1\n        if len(new_classes) != len(set(new_classes)):\n            print(\"iteration\", i, \"could not determine the cluster label mapping, skipping\")\n            continue\n        #apply the mapping by renaming the dataframe columns representing the original labels to the new labels    \n        pred_probs = pred_probs.rename(columns=dict(zip(range(1,8),new_classes)))\n        \n        #add the current prediction probabilities to the overall prediction probabilities\n        predicted_probabilities = predicted_probabilities + pred_probs\n        # lets score the cluster labels each iteration to see if soft voting is helpful\n        score_clusters(X_scaled[best_cols], predicted_probabilities.idxmax(axis=1), verbose=True)\n    \n    #normalise dataframe so each row sums to 1\n    predicted_probabilities = predicted_probabilities.div(predicted_probabilities.sum(axis=1), axis=0)\n    return predicted_probabilities","metadata":{"execution":{"iopub.status.busy":"2022-07-30T15:47:59.969202Z","iopub.execute_input":"2022-07-30T15:47:59.969617Z","iopub.status.idle":"2022-07-30T15:47:59.985327Z","shell.execute_reply.started":"2022-07-30T15:47:59.969586Z","shell.execute_reply":"2022-07-30T15:47:59.984328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_probs = soft_voting(10)","metadata":{"execution":{"iopub.status.busy":"2022-07-30T15:47:59.987327Z","iopub.execute_input":"2022-07-30T15:47:59.987805Z","iopub.status.idle":"2022-07-30T16:13:38.706042Z","shell.execute_reply.started":"2022-07-30T15:47:59.987761Z","shell.execute_reply":"2022-07-30T16:13:38.704778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nscore_clusters(X_scaled[best_cols],pred_probs.idxmax(axis=1), verbose=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-30T16:13:38.708050Z","iopub.execute_input":"2022-07-30T16:13:38.708405Z","iopub.status.idle":"2022-07-30T16:15:17.790975Z","shell.execute_reply.started":"2022-07-30T16:13:38.708373Z","shell.execute_reply":"2022-07-30T16:15:17.789644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def best_class(df):\n    new_df = df.copy()\n    new_df[\"highest_prob\"] = df.max(axis=1)\n    new_df[\"best_class\"] = df.idxmax(axis=1)\n    new_df[\"second_highest_prob\"] = df.apply(lambda x: x.nlargest(2).values[-1], axis=1)\n    new_df[\"second_best_class\"] = df.apply(lambda x: np.where(x == x.nlargest(2).values[-1])[0][0]+1, axis=1)\n    return new_df","metadata":{"execution":{"iopub.status.busy":"2022-07-30T16:15:17.793552Z","iopub.execute_input":"2022-07-30T16:15:17.794370Z","iopub.status.idle":"2022-07-30T16:15:17.801919Z","shell.execute_reply.started":"2022-07-30T16:15:17.794331Z","shell.execute_reply":"2022-07-30T16:15:17.800747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cluster_class_probs = best_class(pred_probs)","metadata":{"execution":{"iopub.status.busy":"2022-07-30T16:15:17.803467Z","iopub.execute_input":"2022-07-30T16:15:17.803839Z","iopub.status.idle":"2022-07-30T16:16:10.449006Z","shell.execute_reply.started":"2022-07-30T16:15:17.803808Z","shell.execute_reply":"2022-07-30T16:16:10.448012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cluster_class_probs.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-30T16:16:10.450339Z","iopub.execute_input":"2022-07-30T16:16:10.451173Z","iopub.status.idle":"2022-07-30T16:16:10.474161Z","shell.execute_reply.started":"2022-07-30T16:16:10.451137Z","shell.execute_reply":"2022-07-30T16:16:10.472802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f,ax = plt.subplots(figsize=(20,7))\nsns.histplot(cluster_class_probs[\"highest_prob\"], bins=100);","metadata":{"execution":{"iopub.status.busy":"2022-07-30T16:16:10.475661Z","iopub.execute_input":"2022-07-30T16:16:10.476011Z","iopub.status.idle":"2022-07-30T16:16:11.042996Z","shell.execute_reply.started":"2022-07-30T16:16:10.475979Z","shell.execute_reply":"2022-07-30T16:16:11.041778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confidence_s = cluster_class_probs.groupby(\"best_class\")[\"highest_prob\"].mean()\nf,ax = plt.subplots(figsize=(8,6))\nsns.barplot(x=confidence_s.index, y = confidence_s.values, palette=sns.color_palette(\"hls\", 7) );\nax.set_ylabel(\"Mean probability of point belonging to target class\");\nax.set_ylim([0.65,0.95]);","metadata":{"execution":{"iopub.status.busy":"2022-07-30T16:16:11.044591Z","iopub.execute_input":"2022-07-30T16:16:11.044910Z","iopub.status.idle":"2022-07-30T16:16:11.291685Z","shell.execute_reply.started":"2022-07-30T16:16:11.044882Z","shell.execute_reply":"2022-07-30T16:16:11.290544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"second_highest_probs_sum = cluster_class_probs.groupby([\"best_class\",\"second_best_class\"])[\"second_highest_prob\"].sum().reset_index()\n\nf,ax = plt.subplots(figsize=(25,12))\nformat_dataframe = pd.DataFrame({\"second_best_class\":range(1,8)})\nfor i in range(1,8):\n    second_best_match_for_i = second_highest_probs_sum.loc[second_highest_probs_sum[\"best_class\"] == i, [\"second_best_class\",\"second_highest_prob\"]]\n    #We merge so that all classes 1 to 7 are available, we do this to keep colours consistent throughout plots\n    plot_df = pd.merge(left=format_dataframe, right=second_best_match_for_i, how=\"left\", on=\"second_best_class\")\n    ax = plt.subplot(2,4,i)\n    sns.barplot(data= plot_df, x=\"second_best_class\", y=\"second_highest_prob\",palette=sns.color_palette(\"hls\", 7) );\n    ax.set_ylabel(\"Probability sum\")\n    ax.set_title(\"Assigned Class: \" + str(i))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-30T16:16:11.293473Z","iopub.execute_input":"2022-07-30T16:16:11.293842Z","iopub.status.idle":"2022-07-30T16:16:12.520073Z","shell.execute_reply.started":"2022-07-30T16:16:11.293810Z","shell.execute_reply":"2022-07-30T16:16:12.518749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confident_predictions = cluster_class_probs.loc[cluster_class_probs[\"highest_prob\"] >= 0.8]\nconfident_predictions_class = confident_predictions[\"best_class\"]\nX_scaled[\"class\"] = confident_predictions_class","metadata":{"execution":{"iopub.status.busy":"2022-07-30T16:16:12.521827Z","iopub.execute_input":"2022-07-30T16:16:12.522529Z","iopub.status.idle":"2022-07-30T16:16:12.542792Z","shell.execute_reply.started":"2022-07-30T16:16:12.522462Z","shell.execute_reply":"2022-07-30T16:16:12.541711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = X_scaled.loc[X_scaled[\"class\"] == X_scaled[\"class\"]]\ntest_df = X_scaled.loc[X_scaled[\"class\"] != X_scaled[\"class\"]]","metadata":{"execution":{"iopub.status.busy":"2022-07-30T16:16:12.544302Z","iopub.execute_input":"2022-07-30T16:16:12.545080Z","iopub.status.idle":"2022-07-30T16:16:12.584705Z","shell.execute_reply.started":"2022-07-30T16:16:12.545041Z","shell.execute_reply":"2022-07-30T16:16:12.583462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_df.drop(columns=\"class\").reset_index(drop=True)\ny = train_df[\"class\"].reset_index(drop=True)\nX_test = test_df.drop(columns=\"class\").reset_index(drop=True)\nX_full = X_scaled.drop(columns=\"class\")","metadata":{"execution":{"iopub.status.busy":"2022-07-30T16:16:12.586398Z","iopub.execute_input":"2022-07-30T16:16:12.587129Z","iopub.status.idle":"2022-07-30T16:16:12.626576Z","shell.execute_reply.started":"2022-07-30T16:16:12.587077Z","shell.execute_reply":"2022-07-30T16:16:12.625552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define models","metadata":{}},{"cell_type":"code","source":"model_et = ExtraTreesClassifier(n_estimators = 3000,\n                                n_jobs = -1,\n                                random_state=54\n                               )","metadata":{"execution":{"iopub.status.busy":"2022-07-30T16:16:12.627877Z","iopub.execute_input":"2022-07-30T16:16:12.628213Z","iopub.status.idle":"2022-07-30T16:16:12.633233Z","shell.execute_reply.started":"2022-07-30T16:16:12.628183Z","shell.execute_reply":"2022-07-30T16:16:12.632484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_lgbm = LGBMClassifier(objective = 'multiclass',\n                            n_estimators = 5000,\n                            random_state = 44,\n                            learning_rate = 0.05,\n                            n_jobs = -1)","metadata":{"execution":{"iopub.status.busy":"2022-07-30T16:16:12.634409Z","iopub.execute_input":"2022-07-30T16:16:12.635467Z","iopub.status.idle":"2022-07-30T16:16:12.644437Z","shell.execute_reply.started":"2022-07-30T16:16:12.635428Z","shell.execute_reply":"2022-07-30T16:16:12.643554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_qda = QuadraticDiscriminantAnalysis()\nmodel_lda = LinearDiscriminantAnalysis()","metadata":{"execution":{"iopub.status.busy":"2022-07-30T16:16:12.645693Z","iopub.execute_input":"2022-07-30T16:16:12.646185Z","iopub.status.idle":"2022-07-30T16:16:12.655119Z","shell.execute_reply.started":"2022-07-30T16:16:12.646153Z","shell.execute_reply":"2022-07-30T16:16:12.653915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_bgmm = BayesianGMMClassifier(\n            n_components=7,\n            random_state = 1,\n            tol =1e-3,\n            covariance_type = 'full',\n            max_iter = 400,\n            n_init=4,\n            init_params='kmeans')","metadata":{"execution":{"iopub.status.busy":"2022-07-30T16:16:12.657467Z","iopub.execute_input":"2022-07-30T16:16:12.657820Z","iopub.status.idle":"2022-07-30T16:16:12.666237Z","shell.execute_reply.started":"2022-07-30T16:16:12.657789Z","shell.execute_reply":"2022-07-30T16:16:12.665369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = {\"ET\":model_et, \"LGBM\":model_lgbm, \"QDA\":model_qda, \"LDA\":model_lda, \"BGMM_C\":model_bgmm}","metadata":{"execution":{"iopub.status.busy":"2022-07-30T16:16:12.667757Z","iopub.execute_input":"2022-07-30T16:16:12.668512Z","iopub.status.idle":"2022-07-30T16:16:12.681932Z","shell.execute_reply.started":"2022-07-30T16:16:12.668446Z","shell.execute_reply":"2022-07-30T16:16:12.680814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Compare Classificatin performance","metadata":{}},{"cell_type":"code","source":"def k_fold_cv(model,X,y, verbose=True):\n    kfold = StratifiedKFold(n_splits = 5, shuffle=True, random_state = 0)\n\n    feature_imp, y_pred_list, y_true_list, acc_list  = [],[],[],[]\n    for fold, (train_index, val_index) in enumerate(kfold.split(X, y)):\n        if verbose: print(\"==fold==\", fold)\n        X_train = X.loc[train_index]\n        X_val = X.loc[val_index]\n\n        y_train = y.loc[train_index]\n        y_val = y.loc[val_index]\n\n        model.fit(X_train,y_train)\n\n        y_pred = model.predict(X_val)\n\n        y_pred_list = np.append(y_pred_list, y_pred)\n        y_true_list = np.append(y_true_list, y_val)\n\n        acc_list.append(accuracy_score(y_pred, y_val))\n        if verbose: print('Acc', accuracy_score(y_pred, y_val))\n\n        try:\n            feature_imp.append(model.feature_importances_)\n        except AttributeError: # if model does not have .feature_importances_ attribute\n            pass # returns empty list\n            \n    return feature_imp, y_pred_list, y_true_list, acc_list, X_val, y_val","metadata":{"execution":{"iopub.status.busy":"2022-07-30T16:16:12.683615Z","iopub.execute_input":"2022-07-30T16:16:12.684850Z","iopub.status.idle":"2022-07-30T16:16:12.697740Z","shell.execute_reply.started":"2022-07-30T16:16:12.684801Z","shell.execute_reply":"2022-07-30T16:16:12.696827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_models():\n    for model_name, model in models.items():\n        print(\"===\",model_name,\"===\")\n        feature_imp, y_pred_list, y_true_list, acc_list, X_val, y_val = k_fold_cv(model=model,X=X,y=y, verbose=False)\n        acc_score = accuracy_score(y_pred_list, y_true_list)\n        print(\"{0:0.4f}\".format(acc_score))","metadata":{"execution":{"iopub.status.busy":"2022-07-30T16:16:12.699808Z","iopub.execute_input":"2022-07-30T16:16:12.700189Z","iopub.status.idle":"2022-07-30T16:16:12.709340Z","shell.execute_reply.started":"2022-07-30T16:16:12.700155Z","shell.execute_reply":"2022-07-30T16:16:12.708161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate_models()","metadata":{"execution":{"iopub.status.busy":"2022-07-30T16:16:12.711018Z","iopub.execute_input":"2022-07-30T16:16:12.711515Z","iopub.status.idle":"2022-07-30T17:12:10.616934Z","shell.execute_reply.started":"2022-07-30T16:16:12.711455Z","shell.execute_reply":"2022-07-30T17:12:10.615646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature importance","metadata":{}},{"cell_type":"code","source":"feature_imp, y_pred_list, y_true_list, acc_list, X_val, y_val = k_fold_cv(model=model_lgbm,X=X,y=y)","metadata":{"execution":{"iopub.status.busy":"2022-07-30T17:12:10.619182Z","iopub.execute_input":"2022-07-30T17:12:10.624819Z","iopub.status.idle":"2022-07-30T17:25:11.011954Z","shell.execute_reply.started":"2022-07-30T17:12:10.624748Z","shell.execute_reply":"2022-07-30T17:25:11.010926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fold_feature_importances(model_importances, column_names, model_name, n_folds = 5, ax=None, boxplot=False):\n    importances_df = pd.DataFrame({\"feature_cols\": column_names, \"importances_fold_0\": model_importances[0]})\n    for i in range(1,n_folds):\n        importances_df[\"importances_fold_\"+str(i)] = model_importances[i]\n    importances_df[\"importances_fold_median\"] = importances_df.drop(columns=[\"feature_cols\"]).median(axis=1)\n    importances_df = importances_df.sort_values(by=\"importances_fold_median\", ascending=False)\n    if ax == None:\n        f, ax = plt.subplots(figsize=(15, 25))\n    if boxplot == False:\n        ax = sns.barplot(data = importances_df, x = \"importances_fold_median\", y=\"feature_cols\", color=\"blue\")\n        ax.set_xlabel(\"Median Feature importance across all folds\");\n    elif boxplot == True:\n        importances_df = importances_df.drop(columns=\"importances_fold_median\")\n        importances_df = importances_df.set_index(\"feature_cols\").stack().reset_index().rename(columns={0:\"feature_importance\"})\n        ax = sns.boxplot(data = importances_df, y = \"feature_cols\", x=\"feature_importance\", color=\"blue\", orient=\"h\")\n        ax.set_xlabel(\"Feature importance across all folds\");\n    plt.title(model_name)\n    ax.set_ylabel(\"Feature Columns\")\n    return ax","metadata":{"execution":{"iopub.status.busy":"2022-07-30T17:25:11.014119Z","iopub.execute_input":"2022-07-30T17:25:11.014613Z","iopub.status.idle":"2022-07-30T17:25:11.027667Z","shell.execute_reply.started":"2022-07-30T17:25:11.014565Z","shell.execute_reply":"2022-07-30T17:25:11.026362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, ax = plt.subplots(figsize=(15, 15))\nfold_feature_importances(model_importances = feature_imp, column_names = X_val.columns, model_name = \"LGBM\", n_folds = 2, ax=ax, boxplot=False);","metadata":{"execution":{"iopub.status.busy":"2022-07-30T17:25:11.029363Z","iopub.execute_input":"2022-07-30T17:25:11.029838Z","iopub.status.idle":"2022-07-30T17:25:11.876596Z","shell.execute_reply.started":"2022-07-30T17:25:11.029793Z","shell.execute_reply":"2022-07-30T17:25:11.875406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"def fit_predict_all():\n    predictions = []\n    model_names = []\n    scores = []\n    for model_name, model in models.items():\n        print(\"===\",model_name,\"===\")\n        model.fit(X[best_cols], y)\n        preds_prob =  model.predict_proba(X_full[best_cols])\n        preds_prob_df = pd.DataFrame(preds_prob, columns=range(1,8), index=X_scaled.index)\n        db, ch, s = score_clusters(X_scaled[best_cols], preds_prob_df.idxmax(axis=1), verbose=True)\n        scores.append((db,ch,s))\n        predictions.append(preds_prob_df)\n        model_names.append(model_name)\n    \n    return predictions, model_names, scores\n    ","metadata":{"execution":{"iopub.status.busy":"2022-07-30T17:25:11.878069Z","iopub.execute_input":"2022-07-30T17:25:11.878428Z","iopub.status.idle":"2022-07-30T17:25:11.888047Z","shell.execute_reply.started":"2022-07-30T17:25:11.878395Z","shell.execute_reply":"2022-07-30T17:25:11.886342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions, model_names, scores = fit_predict_all()","metadata":{"execution":{"iopub.status.busy":"2022-07-30T17:25:11.890095Z","iopub.execute_input":"2022-07-30T17:25:11.890943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cluster_class_probs = cluster_class_probs.loc[:,[1,2,3,4,5,6,7]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions.append(cluster_class_probs)\nmodel_names.append(\"BGMM\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"db, ch, s = score_clusters(X_scaled[best_cols], cluster_class_probs.idxmax(axis=1), verbose=True)\nscores.append((db,ch,s))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Combine Predictions","metadata":{}},{"cell_type":"code","source":"#chosen fairly randomly\npredictions_df = 0.5 * predictions[0] + 1.5 * predictions[1] + 0.5 * predictions[2] + 1.5 * predictions[4] + 0.5 * predictions[5]\n\n#normalise so rows sums to 1\npredictions_df = predictions_df.div(predictions_df.sum(axis=1), axis=0)\npredictions_df = best_class(predictions_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"db, ch, s = score_clusters(X_scaled[best_cols], predictions_df[\"best_class\"], verbose=True)\nscores.append((db,ch,s))\nmodel_names.append(\"combined\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(scores, index=model_names, columns=[\"Davies-Bouldin Index\",\"Calinski-Harabasz Index\",\"Silhouette Coefficient\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f,ax = plt.subplots(figsize=(10,5))\nval_c = predictions_df[\"best_class\"].value_counts()\nsns.barplot(x=val_c.index, y=val_c.values);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca = PCA(random_state = 10)\nX_pca = pca.fit_transform(X_scaled[best_cols])\nPCA_df = pd.DataFrame({\"PCA_1\" : X_pca[:,0], \"PCA_2\" : X_pca[:,1]})   \nPCA_df[\"class\"] = predictions_df[\"best_class\"]\n    \nf,ax = plt.subplots(figsize=(10, 10))\nsns.scatterplot(data = PCA_df, x = \"PCA_1\", y = \"PCA_2\", hue=\"class\", s=2, palette=sns.color_palette(\"hls\", PCA_df[\"class\"].nunique()));","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confidence_s = predictions_df.groupby(\"best_class\")[\"highest_prob\"].mean()\nf,ax = plt.subplots(figsize=(8,6))\nsns.barplot(x=confidence_s.index, y = confidence_s.values, palette=sns.color_palette(\"hls\", 7) );\nax.set_ylabel(\"Mean probability of point belonging to target class\");\nax.set_ylim([0.4,0.95]);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"second_highest_probs_sum = predictions_df.groupby([\"best_class\",\"second_best_class\"])[\"second_highest_prob\"].sum().reset_index()\n\nf,ax = plt.subplots(figsize=(25,12))\nformat_dataframe = pd.DataFrame({\"second_best_class\":range(1,8)})\nfor i in range(1,8):\n    second_best_match_for_i = second_highest_probs_sum.loc[second_highest_probs_sum[\"best_class\"] == i, [\"second_best_class\",\"second_highest_prob\"]]\n    #We merge so that all classes 1 to 7 are available, we do this to keep colours consistent throughout plots\n    plot_df = pd.merge(left=format_dataframe, right=second_best_match_for_i, how=\"left\", on=\"second_best_class\")\n    ax = plt.subplot(2,4,i)\n    sns.barplot(data= plot_df, x=\"second_best_class\", y=\"second_highest_prob\",palette=sns.color_palette(\"hls\", 7) );\n    ax.set_ylabel(\"Probability sum\")\n    ax.set_title(\"Assigned Class: \" + str(i))\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Iterative Classification - BGMM Classifier","metadata":{}},{"cell_type":"code","source":"def update_predictions(predict_number, y):\n    for i in range(predict_number):\n        print(\"=========\", i, \"==========\")\n        X_scaled_sample = X_scaled.sample(50000)\n        y_sample = y.loc[X_scaled_sample.index]\n        \n        bgmmC = BayesianGMMClassifier(\n        n_components=7,\n        random_state = i,\n        tol =1e-3,\n        covariance_type = 'full',\n        max_iter = 300,\n        n_init=3,\n        init_params='kmeans')\n        \n        bgmmC.fit(X_scaled_sample[best_cols], y_sample)\n        \n        pred_probs = bgmmC.predict_proba(X_scaled[best_cols])\n        pred_probs = pd.DataFrame(pred_probs, columns=range(1,8))\n        \n        # lets score the cluster labels each iteration\n        score_clusters(X_scaled[best_cols], pred_probs.idxmax(axis=1), verbose=True)\n        y = pred_probs.idxmax(axis=1)\n        \n    return pred_probs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_probabilities = update_predictions(predict_number=20, y=predictions_df[\"best_class\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_df = best_class(predicted_probabilities)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"second_highest_probs_sum = predictions_df.groupby([\"best_class\",\"second_best_class\"])[\"second_highest_prob\"].sum().reset_index()\n\nf,ax = plt.subplots(figsize=(25,12))\nformat_dataframe = pd.DataFrame({\"second_best_class\":range(1,8)})\nfor i in range(1,8):\n    second_best_match_for_i = second_highest_probs_sum.loc[second_highest_probs_sum[\"best_class\"] == i, [\"second_best_class\",\"second_highest_prob\"]]\n    #We merge so that all classes 1 to 7 are available, we do this to keep colours consistent throughout plots\n    plot_df = pd.merge(left=format_dataframe, right=second_best_match_for_i, how=\"left\", on=\"second_best_class\")\n    ax = plt.subplot(2,4,i)\n    sns.barplot(data= plot_df, x=\"second_best_class\", y=\"second_highest_prob\",palette=sns.color_palette(\"hls\", 7) );\n    ax.set_ylabel(\"Probability sum\")\n    ax.set_title(\"Assigned Class: \" + str(i))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f,ax = plt.subplots(figsize=(10,5))\nval_c = predictions_df[\"best_class\"].value_counts()\nsns.barplot(x=val_c.index, y=val_c.values);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/tabular-playground-series-jul-2022/sample_submission.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### submission[\"Predicted\"] = predictions_df[\"best_class\"]\nsubmission.to_csv('submission.csv', index=False)","metadata":{}}]}